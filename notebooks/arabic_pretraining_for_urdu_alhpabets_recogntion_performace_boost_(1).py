# -*- coding: utf-8 -*-
"""arabic_pretraining_for_urdu_alhpabets_recogntion_performace_boost (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rK6A03hdFs-6up-LNrs79iZfUvM-dzD4

# arabic-pretraining-for-urdu-alphabets-recogntion-performace-boost

#### pre-trained on imagenet

#### Author: Zaryab rahman
#### Date:  4/10/25
"""

!unzip "/content/archive.zip" -d "/content/ahar/"

"""### Imports"""

import os
import time
import json
import logging
import torch
import timm
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from torch import nn
from torch.utils.data import DataLoader, SubsetRandomSampler
from torchvision import datasets, transforms
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from tqdm.auto import tqdm

"""### Config"""

CONFIG = {
    "data_path": "/content/ahar",

    "num_classes": 28,
    "batch_size": 64,
    "image_size": 224,
    "num_epochs": 50,
    "learning_rate": 0.0001,
    "early_stopping_patience": 5,
    "validation_split": 0.15,

    "checkpoints_dir": "/content/drive/MyDrive/uhar/arabic_pretrained_models/",

    "models_to_evaluate": [
        "swin_tiny_patch4_window7_224",
        "deit_tiny_distilled_patch16_224",
    ]
}

os.makedirs(CONFIG["checkpoints_dir"], exist_ok=True)

"""### setup device, logging, and directories


"""

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

#os.makedirs(CONFIG["results_dir"], exist_ok=True)
os.makedirs(CONFIG["checkpoints_dir"], exist_ok=True)

logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    handlers=[
                        logging.FileHandler("experiment_log.log"),
                        logging.StreamHandler()
                    ])

logging.info(f"Using device: {DEVICE}")

"""### EarlyStopping"""

class EarlyStopping:
    def __init__(self, patience=5, min_delta=0, checkpoint_path='checkpoint.pth'):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.inf
        self.checkpoint_path = checkpoint_path

    def __call__(self, val_loss, model):
        score = -val_loss
        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
        elif score < self.best_score + self.min_delta:
            self.counter += 1
            logging.info(f'earlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model)
            self.counter = 0

    def save_checkpoint(self, val_loss, model):
        logging.info(f'validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving best model...')
        torch.save(model.state_dict(), self.checkpoint_path)
        self.val_loss_min = val_loss

"""### Data Loading and Verification

"""

import os
import glob
from PIL import Image
from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler
from torchvision import transforms
import numpy as np
import logging

class ArabicImageDatasetFromFile(Dataset):
    def __init__(self, data_dir, transform=None):
        self.transform = transform
        self.image_paths = sorted(glob.glob(os.path.join(data_dir, "*", "*.png")))

        self.labels = [int(p.split('_')[-1].split('.')[0]) - 1 for p in self.image_paths]

        self.class_names = [str(i) for i in range(len(set(self.labels)))]
        self.class_to_idx = {name: i for i, name in enumerate(self.class_names)}

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert("RGB")
        label = self.labels[idx]
        if self.transform:
            image = self.transform(image)
        return image, label

def create_arabic_dataloaders(config):
    data_transform = transforms.Compose([
        transforms.Resize((config["image_size"], config["image_size"])),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    train_dir = "/content/ahar/train_organized"
    test_dir = "/content/ahar/test_organized"

    if not os.path.exists(train_dir):
        logging.error(f"Organized training directory not found at: {train_dir}")
        return None, None, None

    full_train_dataset = ArabicImageDatasetFromFile(train_dir, transform=data_transform)

    logging.info("Using Custom Dataset that reads labels from FILENAMES.")
    print("Class to Index Mapping (based on unique labels found):")
    print(full_train_dataset.class_to_idx)

    val_split = config["validation_split"]
    dataset_size = len(full_train_dataset)
    indices = list(range(dataset_size))
    split = int(np.floor(val_split * dataset_size))
    np.random.seed(42)
    np.random.shuffle(indices)
    train_indices, val_indices = indices[split:], indices[:split]

    train_sampler = SubsetRandomSampler(train_indices)
    val_sampler = SubsetRandomSampler(val_indices)

    train_loader = DataLoader(
        full_train_dataset, batch_size=config["batch_size"], sampler=train_sampler,
        num_workers=2, pin_memory=True
    )
    val_loader = DataLoader(
        full_train_dataset, batch_size=config["batch_size"], sampler=val_sampler,
        num_workers=2, pin_memory=True
    )

    test_loader = None
    if os.path.exists(test_dir):
         test_dataset = ArabicImageDatasetFromFile(test_dir, transform=data_transform)
         test_loader = DataLoader(
             test_dataset, batch_size=config["batch_size"], shuffle=False,
             num_workers=2, pin_memory=True
         )
         logging.info(f"Test data loader created with {len(test_dataset)} images.")
    else:
        logging.warning(f"Organized test directory not found at: {test_dir}. Skipping test data loading.")

    logging.info(f"Data loaders created: {len(train_indices)} train images, {len(val_indices)} validation images.")
    return train_loader, val_loader, test_loader

from torchvision.utils import make_grid

train_loader, val_loader, test_loader = create_arabic_dataloaders(CONFIG)

if train_loader:
    images, labels = next(iter(train_loader))

    images = images[:16]
    labels = labels[:16]


    grid = make_grid(images, nrow=4)

    plt.figure(figsize=(8, 8))
    plt.imshow(grid.permute(1, 2, 0))
    plt.axis('off')
    plt.show()
else:
    logging.error("training data loader not created.")

"""### Core Training and Evaluation Functions"""

def train_model(model, model_name, config, train_dataloader, val_dataloader):
    loss_fn = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=config["learning_rate"])

    best_model_path = os.path.join(config["checkpoints_dir"], f"{model_name}_best_model.pth")
    early_stopper = EarlyStopping(patience=config["early_stopping_patience"], checkpoint_path=best_model_path)

    start_time = time.time()
    for epoch in range(config["num_epochs"]):
        model.train()
        train_loss, train_acc = 0, 0
        train_pbar = tqdm(train_dataloader, desc=f"Epoch {epoch+1}/{config['num_epochs']} [Train]", leave=False)
        for X, y in train_pbar:
            X, y = X.to(DEVICE), y.to(DEVICE)
            y_pred = model(X)
            loss = loss_fn(y_pred, y)
            train_loss += loss.item()
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)
            train_acc += (y_pred_class == y).sum().item() / len(y_pred)

        train_loss /= len(train_dataloader)
        train_acc /= len(train_dataloader)

        model.eval()
        val_loss, val_acc = 0, 0
        val_pbar = tqdm(val_dataloader, desc=f"Epoch {epoch+1}/{config['num_epochs']} [Val]", leave=False)
        with torch.no_grad():
            for X, y in val_pbar:
                X, y = X.to(DEVICE), y.to(DEVICE)
                y_pred = model(X)
                val_loss += loss_fn(y_pred, y).item()
                y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)
                val_acc += (y_pred_class == y).sum().item() / len(y_pred)

        val_loss /= len(val_dataloader)
        val_acc /= len(val_dataloader)

        print(f"Epoch: {epoch+1} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}")

        early_stopper(val_loss, model)
        if early_stopper.early_stop:
            logging.info("Early stopping triggered.")
            break

    total_time = time.time() - start_time
    logging.info(f"Training completed for {model_name} in {total_time:.2f} seconds.")

"""### Visualization Functions"""

train_loader_arabic, val_loader_arabic, test_loader_arabic = create_arabic_dataloaders(CONFIG)

if train_loader_arabic and val_loader_arabic:
    for model_name in CONFIG["models_to_evaluate"]:
        logging.info(f"\n{'='*80}\nstarting pretrsining for : {model_name}\n{'='*80}")

        model = timm.create_model(
            model_name,
            pretrained=True,
            num_classes=CONFIG["num_classes"]
        ).to(DEVICE)

        train_model(model, model_name, CONFIG, train_loader_arabic, val_loader_arabic)

        logging.info(f"\n{'='*80}\npre-training done for : {model_name}. best weights saved.\n{'='*80}")

    logging.info("pre-training done.")
else:
    logging.error("Could not create Arabic data loaders. Halting pre-training.")

def validate_dataloader_labels(dataloader, num_samples_to_check=10):
    dataset = dataloader.dataset

    if hasattr(dataset, 'sampler'):
      indices = list(dataset.sampler)
      samples_to_check = [dataset.samples[i] for i in indices[:num_samples_to_check]]
    else:
      samples_to_check = dataset.samples[:num_samples_to_check]


    mismatch_found = False
    for i, (image_path, label) in enumerate(samples_to_check):
        folder_name = os.path.basename(os.path.dirname(image_path))

        print(f"Sample {i+1}:")
        print(f"image path: .../{folder_name}/{os.path.basename(image_path)}")
        print(f"assigned label: {label}")

        if str(label) != folder_name:
            print("mismatch!")
            mismatch_found = True
        else:
            print("ok")

    print("-" * 80)
    if mismatch_found:
        print("data pipline is incorrect")
    else:
        print("validation passed")
    print("=" * 80)


validate_dataloader_labels(train_loader)

import matplotlib.pyplot as plt
from torchvision.utils import make_grid
import numpy as np

def show_image_batch(dataloader):
    images, labels = next(iter(dataloader))
    grid = make_grid(images, nrow=8)

    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])

    img_unnormalized = grid.permute(1, 2, 0).numpy()
    img_unnormalized = std * img_unnormalized + mean
    img_unnormalized = np.clip(img_unnormalized, 0, 1)

    plt.figure(figsize=(20, 10))
    plt.imshow(img_unnormalized)
    plt.title("Final Sanity Check: Sample Images from the DataLoader")
    plt.axis('off')
    plt.show()

    print("="*80)
    print("Labels for the first 16 images (parsed from filenames):")
    print(labels[:16].numpy())
    print("="*80)

show_image_batch(train_loader)

import os
import shutil
from tqdm.auto import tqdm
source_train_dir = "/content/ahar/train images 13440x32x32/train"

organized_train_dir = "/content/ahar/train_organized"

os.makedirs(organized_train_dir, exist_ok=True)

for i in range(28):
    os.makedirs(os.path.join(organized_train_dir, str(i)), exist_ok=True)

print("reorganizing training files...")

image_files = [f for f in os.listdir(source_train_dir) if f.endswith('.png')]

for filename in tqdm(image_files):
    try:
        label = int(filename.split('_')[-1].split('.')[0]) - 1

        source_path = os.path.join(source_train_dir, filename)
        destination_path = os.path.join(organized_train_dir, str(label), filename)

        # Move the file
        shutil.move(source_path, destination_path)
    except (ValueError, IndexError) as e:
        print(f"Could not parse label from {filename}. Skipping. Error: {e}")

print("file reorganization complete.")

import os
import shutil
from tqdm.auto import tqdm

source_train_dir = "/content/ahar/test images 3360x32x32/test"

organized_train_dir = "/content/ahar/test_organized"

os.makedirs(organized_train_dir, exist_ok=True)

for i in range(28):
    os.makedirs(os.path.join(organized_train_dir, str(i)), exist_ok=True)

print("reorganizing training files...")
image_files = [f for f in os.listdir(source_train_dir) if f.endswith('.png')]
for filename in tqdm(image_files):
    try:
        label = int(filename.split('_')[-1].split('.')[0]) - 1 # This is your logic
        source_path = os.path.join(source_train_dir, filename)
        destination_path = os.path.join(organized_train_dir, str(label), filename)
        shutil.move(source_path, destination_path)
    except (ValueError, IndexError) as e:
        print(f"Could not parse label from {filename}. Skipping. Error: {e}")

print("file reorganization complete.")